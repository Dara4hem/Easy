# Comprehensive Quality Comparison Report

Comparing synthetic review quality across models and against real data.

## Datasets

- **OpenAI (gpt-4.1-mini)**: 200 reviews from `data\synthetic\dev_tools_openai_scored.jsonl`
- **Qwen3-30B (Ollama)**: 300 reviews from `data\synthetic\dev_tools_qwen30b_scored.jsonl`
- **Real (G2)**: 50 reviews from `data\real\postman_g2_as_reviews.jsonl`

## Expected Rating Distribution (from config)

| Rating | Expected % |
|--------|-----------|
| 5★ | 35.0% |
| 4★ | 40.0% |
| 3★ | 20.0% |
| 2★ | 4.0% |
| 1★ | 1.0% |

## Quality Metrics Comparison

| Metric | OpenAI (gpt-4.1-mini) | Qwen3-30B (Ollama) | Real (G2) |
|--------|--------|--------|--------|
| Vocab Diversity | 0.841 | 0.799 | 0.619 |
| Semantic Novelty | 0.638 | 0.619 | 0.691 |
| Domain Realism | 0.254 | 0.396 | 0.260 |
| Rejection Rate | 0.010 | 0.017 | 0.060 |
| High Rating Ratio (≥4★) | 0.715 | 0.737 | 1.000 |
| Low Rating Ratio (≤2★) | 0.060 | 0.037 | 0.000 |
| Rating Skew Score | 0.0091 | 0.0009 | 0.0842 |
| Avg Sentiment | 0.010 | 0.017 | 0.019 |

## Rating Distribution Comparison

| Rating | OpenAI (gpt-4.1-mini) | Qwen3-30B (Ollama) | Real (G2) |
|--------|--------|--------|--------|
| 5★ | 54 (27.0%) | 104 (34.7%) | 20 (40.0%) |
| 4★ | 89 (44.5%) | 117 (39.0%) | 30 (60.0%) |
| 3★ | 45 (22.5%) | 68 (22.7%) | 0 (0.0%) |
| 2★ | 9 (4.5%) | 10 (3.3%) | 0 (0.0%) |
| 1★ | 3 (1.5%) | 1 (0.3%) | 0 (0.0%) |

## Key Insights

- **Highest vocabulary diversity**: OpenAI (gpt-4.1-mini) (0.841)
- **Highest domain realism**: Qwen3-30B (Ollama) (0.396)
- **Lowest rejection rate**: OpenAI (gpt-4.1-mini) (0.010)

### Rating Distribution Alignment
- **OpenAI (gpt-4.1-mini)** rating skew score: `0.0091` (lower = closer to expected)
- **Qwen3-30B (Ollama)** rating skew score: `0.0009` (lower = closer to expected)
- **Real (G2)** rating skew score: `0.0842` (lower = closer to expected)

---

*Report generated by `python -m synthetic_reviews.compare_cli`*